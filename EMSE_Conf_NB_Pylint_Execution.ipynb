{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87856640-298e-4391-95f2-9c3d9c29f4b1",
   "metadata": {},
   "source": [
    "# Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9cf37d-64b6-4c48-9700-348f9646f2dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import os\n",
    "import ast\n",
    "import astor\n",
    "import logging\n",
    "import codecs\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import pylint.lint\n",
    "import nbformat\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951965bb-8e9a-44a4-92e1-2c8f0755f047",
   "metadata": {},
   "source": [
    "# Data Directory Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fcdd2f-7eba-4028-ac1f-7a6a549ac924",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nbformat "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19921cd-5c1d-42d2-ab83-7cb72d72296a",
   "metadata": {},
   "source": [
    "In this study, data are split into 10 parts to handle them easily.</br> Use the directory pathonly if the data are gathered in a single directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a11adc7-4d5d-428e-8a37-e616170816a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint_txt_path = ['data_directory']\n",
    "pylint_txt_path = ['nb_data/part_0/KT_dataset/','nb_data/part_1/KT_dataset/','nb_data/part_2/KT_dataset/',\n",
    "                   'nb_data/part_3/KT_dataset/','nb_data/part_4/KT_dataset/','nb_data/part_5/KT_dataset/',\n",
    "                   'nb_data/part_6/KT_dataset/','nb_data/part_7/KT_dataset/','nb_data/part_8/KT_dataset/',\n",
    "                   'nb_data/part_9/KT_dataset/'] \n",
    "\n",
    "output_path=\"result/all_pylint_nb_text/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e2e71f-a9ec-4cf4-978f-837f74e66373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_filename(path, extension):\n",
    "    notebook_filenames_list = glob.glob(os.path.join(path, extension))\n",
    "    \n",
    "    print(len(notebook_filenames_list))\n",
    "    return notebook_filenames_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29355a81-50db-4596-82e7-e7feb9246bc3",
   "metadata": {},
   "source": [
    "# NB Pylint Conversion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205966af-36e2-4576-b6f4-b73c7aafa47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_for_issues, code_cells, line_numbers, issue_codes = [], [], [], []\n",
    "filenames_for_rating, ratings = [], []\n",
    "outputs_files = []\n",
    "\n",
    "file_count = 24876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2752df48-9759-4d51-a4f4-659ea1c1a278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pylint_analysis_single_file(target_nb):\n",
    "   \n",
    "    original_filename = target_nb.replace(\".ipynb\",\"\")\n",
    "    output_pylint_filename = original_filename + \"_pylintnb.txt\"\n",
    "    \n",
    "    try:\n",
    "#         this is the line for parallel execution \n",
    "        output = ! python3 -m nbqa pylint $target_nb >> $output_pylint_filename\n",
    "        print (target_nb)\n",
    "            \n",
    "    except Exception as e:\n",
    "        with open(\"exception_log.txt\", \"a\") as file_object:\n",
    "            write_message = str(target_nb) + \" : \" + str(e) + \"\\n\"\n",
    "            file_object.write(write_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc8f04ca-8aa4-46f5-90ef-bddd95d8568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_conversion_batch_pylint(target_notebook_files):\n",
    "\n",
    "    processes = []\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for target_file in target_notebook_files:\n",
    "            processes.append(executor.submit(pylint_analysis_single_file, target_file))\n",
    "    \n",
    "    with open(\"filecount.txt\", \"a\") as file_object:\n",
    "        file_object.write('Done for pylint_txt_path[2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc7e3a-ede6-42d6-939c-061029a27685",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_notebook_files = get_list_of_filename(pylint_txt_path[9], '*.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f0587-7d62-4b76-a14a-99599e5d4a0b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_data/part_8/KT_dataset/abyaadrafid_bangla-pretrained-awd-lstm.ipynb\n",
      "nb_data/part_8/KT_dataset/supersilverdave_sql-scavhunt-day-1-the-basics.ipynb\n",
      "nb_data/part_8/KT_dataset/trgosselin14_notebookf9397b717d.ipynb\n",
      "nb_data/part_8/KT_dataset/kerneler_starter-modelfinal-0f5910b1-e.ipynb\n",
      "nb_data/part_8/KT_dataset/kerneler_starter-new-york-taxi-derived-data-4ff5098f-7.ipynb\n",
      "nb_data/part_8/KT_dataset/gokhancicek_my-first-data-science-homework.ipynb\n",
      "nb_data/part_8/KT_dataset/iamfuture_support-group.ipynb\n",
      "nb_data/part_8/KT_dataset/darcnyte_titanic-dataset.ipynb\n",
      "nb_data/part_8/KT_dataset/vijayshinva_iris-tensorflow-basic-softmax-regression.ipynb\n",
      "nb_data/part_8/KT_dataset/lachonman_wgan-repo.ipynb\n",
      "nb_data/part_8/KT_dataset/olgabelitskaya_pytorch-practice.ipynb\n",
      "nb_data/part_8/KT_dataset/aglaserschoff_pneumoniaags-gpu.ipynb\n"
     ]
    }
   ],
   "source": [
    "file_conversion_batch_pylint(target_notebook_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc588b97-7809-42b0-aad6-e509013e9608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nb_data/part_1/KT_dataset/cm57201_exercise-nested-and-repeated-data.ipynb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_list_of_filename(pylint_txt_path[1], '*.ipynb')[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f7ef6f-19cb-4374-9c15-7ababb45e751",
   "metadata": {
    "tags": []
   },
   "source": [
    "['************* Module basselali_simple', 'nb_data/part_0/KT_dataset/basselali_simple.ipynb:cell_1:3:57: C0303: Trailing whitespace (trailing-whitespace)', 'nb_data/part_0/KT_dataset/basselali_simple.ipynb:cell_1:9:0: C0301: Line too long (112/100) (line-too-long)', 'nb_data/part_0/KT_dataset/basselali_simple.ipynb:cell_1:0:0: C0114: Missing module docstring (missing-module-docstring)', 'nb_data/part_0/KT_dataset/basselali_simple.ipynb:cell_1:11:0: C0411: standard import \"from subprocess import check_output\" should be placed before \"import numpy as np\" (wrong-import-order)', 'nb_data/part_0/KT_dataset/basselali_simple.ipynb:cell_1:5:0: W0611: Unused numpy imported as np (unused-import)', '', '-----------------------------------', 'Your code has been rated at 1.67/10', '']\n",
    "['************* Module efstathiasdrolia_week-4-instacart-notebook', 'nb_data/part_0/KT_dataset/efstathiasdrolia_week-4-instacart-notebook.ipynb:cell_1:2:48: C0303: Trailing whitespace (trailing-whitespace)', 'nb_data/part_0/KT_dataset/efstathiasdrolia_week-4-instacart-notebook.ipynb:cell_1:0:0: C0114: Missing module docstring (missing-module-docstring)', 'nb_data/part_0/KT_dataset/efstathiasdrolia_week-4-instacart-notebook.ipynb:cell_1:0:0: C0103: Module name \"efstathiasdrolia_week-4-instacart-notebook\" doesn\\'t conform to snake_case naming style (invalid-name)', 'nb_data/part_0/KT_dataset/efstathiasdrolia_week-4-instacart-notebook.ipynb:cell_3:1:0: W0104: Statement seems to have no effect (pointless-statement)', 'nb_data/part_0/KT_dataset/efstathiasdrolia_week-4-instacart-notebook.ipynb:cell_8:1:0: W0104: Statement seems to have no effect (pointless-statement)', 'nb_data/part_0/KT_dataset/efstathiasdrolia_week-4-instacart-notebook.ipynb:cell_15:2:0: W0104: Statement seems to have no effect (pointless-statement)', 'nb_data/part_0/KT_dataset/efstathiasdrolia_week-4-instacart-notebook.ipynb:cell_25:2:0: W0104: Statement seems to have no effect (pointless-statement)', \"nb_data/part_0/KT_dataset/efstathiasdrolia_week-4-instacart-notebook.ipynb:cell_27:2:0: R0402: Use 'from matplotlib import ticker' instead (consider-using-from-import)\", 'nb_data/part_0/KT_dataset/efstathiasdrolia_week-4-instacart-notebook.ipynb:cell_27:2:0: C0413: Import \"import matplotlib.ticker as ticker\" should be placed at the top of the module (wrong-import-position)', 'nb_data/part_0/KT_dataset/efstathiasdrolia_week-4-instacart-notebook.ipynb:cell_27:2:0: C0412: Imports from package matplotlib are not grouped (ungrouped-imports)', '', '-----------------------------------', 'Your code has been rated at 8.25/10', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b3c5c50-5b84-45c4-8b69-a718e77419c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {'collapsed': False},\n",
       "   'outputs': [],\n",
       "   'source': '# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load in \\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\\n\\n# Input data files are available in the \"../input/\" directory.\\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\\n\\nfrom subprocess import check_output\\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\\nallData = pd.read_csv(\\'../input/data.csv\\')\\nprint(allData.describe(include=\\'all\\'))\\n# Any results you write to the current directory are saved as output.'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {'collapsed': False},\n",
       "   'outputs': [],\n",
       "   'source': ''}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = nbformat.read('nb_data/part_0/KT_dataset/basselali_simple.ipynb', as_version=4)\n",
    "nb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2016cd7-9ca0-439d-9cd8-2d75ef58890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 # This Python 3 environment comes with many helpful analytics libraries installed\n",
      "1 # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
      "1 # For example, here's several helpful packages to load in \n",
      "1 \n",
      "1 import numpy as np # linear algebra\n",
      "1 import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
      "1 \n",
      "1 # Input data files are available in the \"../input/\" directory.\n",
      "1 # For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
      "1 \n",
      "1 from subprocess import check_output\n",
      "1 print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
      "1 allData = pd.read_csv('../input/data.csv')\n",
      "1 print(allData.describe(include='all'))\n",
      "1 # Any results you write to the current directory are saved as output.\n",
      "2 \n"
     ]
    }
   ],
   "source": [
    "cell_counter = 1\n",
    "for i in nb['cells']:\n",
    "    if (i['cell_type'] == 'code'):\n",
    "        line_counter = 1\n",
    "        for line in i['source'].split('\\n'):\n",
    "            print(cell_counter, line)\n",
    "    \n",
    "    cell_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a94da2e-6d1f-4d1d-8f59-d17e42762476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "print(pylint.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
